export estimate_offset,
       one_path_dyn_b,
       get_data_err_var,
       optimize_b_dyn,
       test_func_train,
       one_path_optimize_dyn_b,
       stat_optimize_dyn_b,
       train_NN_int

# Remarks: T‚Çã  = -offset*h
estimate_offset(tm::AbstractFloat, N::Int) = convert(typeof(N), abs(round(N*tm)))

"""
Suppose d/dt J_t = V_t. Given values of V_t, we return J_t by midpoint rule.
"""
function integrate_over_time(N::Int, h::T,
        Vf::Vector{T}, Vb::Vector{T}) where T<:AbstractFloat
    Jf = zeros(T, N+1); Jb = zeros(T, N+1)
    for k = 2:(N+1)
        Jf[k] = Jf[k-1] + (Vf[k] + Vf[k-1])/2*h
        Jb[k] = Jb[k-1] - (Vb[k] + Vb[k-1])/2*h
    end
    return vcat(reverse(Jb)[1:N], Jf)
end

"""
This function generates a sample of the estimator.
"""
function one_path_dyn_b(para::Dyn{T},
    test_func::AbstractArray{},
    test_func_para::AbstractArray{},
    N::Int, offset::Int,
    init_func::Function, init_func_arg,
    solver::Function;
#    T = Float64,
    verbose=false, shiftprotect=true) where T<:AbstractFloat

    X‚ÇÄ = init_func(init_func_arg)
    verbose ? println(X‚ÇÄ) : nothing

    h = T(1/N)
    Vf, _ = time_integrate((x,t,p)-> p(x), para,
                           X‚ÇÄ, T(0.0), T(1.0), N, solver, test_func, test_func_para)
    Vb, _ = time_integrate((x,t,p)->(-1)*p(x), para,
                           X‚ÇÄ, T(0.0), T(1.0), N, solver, test_func, test_func_para)
    Value = hcat((reverse(Vb[1:2,:], dims=2))[:,1:N], Vf[1:2,:])

    Jaco = integrate_over_time(N, h, Vf[3,:], Vb[3,:])
    if ~shiftprotect
        F‚ÇÄ = exp.(Value[1,:] .+ Jaco)
        F‚ÇÅ = exp.(Value[2,:] .+ Jaco)
    else
        # as we only need the ratio of F‚ÇÅ/F‚ÇÄ,
        # we can divide the numerator and denominator
        # by the same value without affecting the conclusion
        F‚ÇÄ = Value[1,:] .+ Jaco
        F‚ÇÅ = Value[2,:] .+ Jaco
        shift = maximum(F‚ÇÄ)
        F‚ÇÄ = F‚ÇÄ .- shift
        F‚ÇÅ = F‚ÇÅ .- shift
        F‚ÇÄ = exp.(F‚ÇÄ)
        F‚ÇÅ = exp.(F‚ÇÅ)
    end

    # todo: a minor speed-up is possible for computing B. Todo later.
    # trapezoidal rule
    B = [Trapezoidal(F‚ÇÄ[(j+offset-N):(j+offset)],h)
         for j in (N+1-offset):(2*N+1-offset)]
    F‚ÇÅB = F‚ÇÅ[(N+1-offset):(2*N+1-offset)]./B

    return Trapezoidal(F‚ÇÅB, h), F‚ÇÄ, F‚ÇÅ, Jaco
end

"""
Return relative error and variance for statistics.
"""
function get_data_err_var(U‚ÇÄ::Potential{T}, U‚ÇÅ::Potential{T},
        para::Dyn,
        N::Int64,
        offset::Int,
        numsample::Int;
        œïname="msq", œïœµ=T(1.0e-3),
        fixed_sampler_func=nothing,
        solver=RK4,
        shiftprotect=true,
        ptype="threads") where T<:AbstractFloat

    œï = get_Œ¶(œïname, œïœµ)

    test_func = [(x,t,p)->-U‚ÇÄ(x), (x,t,p)->-U‚ÇÅ(x), (x,t,p)-> divg_b(p, x)]
    test_func_para = [nothing nothing para]

    if fixed_sampler_func == nothing
        # the default way to generate sample
        init_func = j->sampler(U‚ÇÄ,1)[:]
    else
        # if one wants to use a fix collection of samples, e.g., denoted as pts,
        # then we can simply choose fixed_sampler_func = j-> pts[j]
        init_func = j->fixed_sampler_func(j)
    end

    if ptype == "pmap"
        data = pmap(j->one_path_dyn_b(para, test_func, test_func_para,
                                  N, offset, init_func, j, solver,
                                  T=T, shiftprotect=shiftprotect)[1],
                    1:numsample)
    else
        data = zeros(T, numsample)
        Threads.@threads for j = 1:numsample
            data[j] = one_path_dyn_b(para, test_func, test_func_para,
                            N, offset, init_func, j, solver,
                            T=T, shiftprotect=shiftprotect)[1];
        end
    end
    data, percent = remove_nan(data) # remove NaN
    if percent > 1.0e-4
        @warn(@sprintf("%10.2E percent of data is removed due to NaN", percent))
    end

    m = mean(data)
    #m2 = mean(data.^2)
    m2 = mean(œï.f(data))
    #return data, m, m2 - m^2
    return data, m, m2 - œï.f(m)
end

"""
This function implements the following dyanmics:
- dX‚Çú = b(X‚Çú),
- dY_t = ‚àáb(X_t) Y_t + Œ¥b(X_t), where Œ¥b = db/dŒ∏.

Input:
- XY is the state of [X, Y‚ÇÅ, Y‚ÇÇ, ‚ãØ, Y‚Çò], where m is the number of parameters;
- flow is the neural network representation of ùêõ;

Output:
- the time derivative [ÃádX, dY‚ÇÅ,‚ãØ, dY‚Çò].
"""
function optimize_b_dyn(XY::Array{T}, flow::DynTrain{T}) where T<:AbstractFloat
    M = flow.total_num_para
    x = XY[:,1]
    dXY = zeros(T, size(XY))
    dXY[:,1] = flow(x)
    grad_b = ‚àáb(flow, x)
    dXY[:,2:(1+M)] = grad_b*XY[:,2:(1+M)] + grad_b_wrt_para(flow, x)
    return dXY
end

"""
test_func_train(...) is a generic template to generate test functions.
"""
function test_func_train(XY::AbstractMatrix{T}, p::DynTrain{T},
        U‚ÇÄ::Potential{T}, U‚ÇÅ::Potential{T}) where T<:AbstractFloat

    num_para = p.num_para
    M = p.total_num_para

    x = XY[:,1]
    œï = zeros(T, 3*(1 + M))
    œï[1:3] = [-U‚ÇÄ(x), -U‚ÇÅ(x), divg_b(p, x)]

    ‚àáU‚ÇÄ = ‚àáU(U‚ÇÄ, x)
    ‚àáU‚ÇÅ = ‚àáU(U‚ÇÅ, x)
    graddivgb = grad_divg_b(p, x) # the term ‚àá(‚àá‚ãÖb)

    divgbdŒ∏ = grad_divg_wrt_para(p,x)
    for k = 1:p.total_num_para
        œï[3*k+1] = -dot(‚àáU‚ÇÄ, XY[:,k+1])
        œï[3*k+2] = -dot(‚àáU‚ÇÅ, XY[:,k+1])
        œï[3*k+3] = dot(graddivgb, XY[:,k+1]) + divgbdŒ∏[k]
    end

    return œï
end

"""
It gives a single trajectory estimation for Z‚ÇÅ/Z‚ÇÄ and
the derivatives of the secomd moment with respect to parameters.
"""
function one_path_optimize_dyn_b(flow::DynTrain{T},
    test_func::Function,
    test_func_para,
    N::Int, offset::Int,
    init_func::Function,
    init_func_arg,
    solver::Function, œï::Œ¶{T};
    verbose::Bool=false,
    shiftprotect::Bool=true) where T<:AbstractFloat

    n = flow.dim
    h = T(1/N)
    M = flow.total_num_para

    # initialize a particle.
    X‚ÇÄ = init_func(init_func_arg)
    verbose ? println(X‚ÇÄ) : nothing

    Vf,_ = time_integrate((x,t,p) -> optimize_b_dyn(x,p), flow,
        hcat(X‚ÇÄ,zeros(T, n, M)),
        T(0.0), T(1.0), N, solver,
        test_func, test_func_para, 3*(1+M))
    Vb,_ = time_integrate((x,t,p) -> (-1)*optimize_b_dyn(x,p), flow,
        hcat(X‚ÇÄ,zeros(T, n, M)),
        T(0.0), T(1.0), N, solver,
        test_func, test_func_para, 3*(1+M))
    Value = hcat((reverse(Vb, dims=2))[:,1:N], Vf)

    # Update F
    Jaco = integrate_over_time(N, h, Vf[3,:], Vb[3,:])
    if ~shiftprotect
        F‚ÇÄ = exp.(Value[1,:] .+ Jaco)
        F‚ÇÅ = exp.(Value[2,:] .+ Jaco)
    else
        F‚ÇÄ = Value[1,:] .+ Jaco
        F‚ÇÅ = Value[2,:] .+ Jaco
        shift = maximum(F‚ÇÄ)
        F‚ÇÄ = F‚ÇÄ .- shift
        F‚ÇÅ = F‚ÇÅ .- shift
        F‚ÇÄ = exp.(F‚ÇÄ)
        F‚ÇÅ = exp.(F‚ÇÅ)
    end

    # update G‚ÇÄ and G‚ÇÅ.
    G‚ÇÄ = zeros(T, M, 2*N+1)
    G‚ÇÅ = zeros(T, M, 2*N+1)
    for i = 1:M
        J = integrate_over_time(N, h, Vf[3+3*i,:], Vb[3+3*i,:])
        G‚ÇÄ[i,:] = Value[3*i+1,:] + J
        G‚ÇÅ[i,:] = Value[3*i+2,:] + J
        G‚ÇÄ[i,:] = G‚ÇÄ[i,:].*F‚ÇÄ
        G‚ÇÅ[i,:] = G‚ÇÅ[i,:].*F‚ÇÅ
    end

    # get estimator
    TmTp = (N+1-offset):(2*N+1-offset) # range for T‚Çã to T‚Çä
    B = [Trapezoidal(F‚ÇÄ[(j+offset-N):(j+offset)],h) for j in TmTp]
    estimator = Trapezoidal(F‚ÇÅ[TmTp]./B, h)

    # derivatives
    deri = zeros(T, M)
    for i = 1:M
        Int_G‚ÇÄ = [Trapezoidal(G‚ÇÄ[i,(j+offset-N):(j+offset)], h) for j in TmTp]
        tmp‚ÇÅ = Trapezoidal(G‚ÇÅ[i,TmTp]./B, h)
        tmp‚ÇÇ = Trapezoidal(F‚ÇÅ[TmTp].*Int_G‚ÇÄ./(B.^2), h)
        #deri[i] = 2*estimator*( tmp‚ÇÅ - tmp‚ÇÇ )
        deri[i] = œï.fderi(estimator)*( tmp‚ÇÅ - tmp‚ÇÇ )
    end

    return vcat(estimator, deri)
end


"""
This function returns first and second order moment of estimator and derivative with respect to
    the parameter (stored inside flow.para_list).

Input:
- N is the number of grid points in time
- offset encodes the starting time T‚Çã: the relation is that T‚Çã = -offset*(1/N)
- numsample is the sample size

Output: (fst_m, sec_m) where
- fst_m: first moment of A, ‚àÇ(A^2)/‚àÇŒ∏‚ÇÅ, ‚àÇ(A^2)/‚àÇŒ∏‚ÇÇ, ‚ãØ,  ‚àÇ(A^2)/‚àÇŒ∏‚Çó
where l is the number of parameters where A is the estimator herein (see paper)
- sec_m: second moment of the above

"""
function stat_optimize_dyn_b(U‚ÇÄ::Potential{T}, U‚ÇÅ::Potential{T},
        flow::DynTrain{T}, N::Int,
        offset::Int, numsample::Int;
        œïname="msq", œïœµ::T=T(1.0e-3),
        fixed_sampler_func=nothing,
        solver::Function=RK4,
        ptype="threads") where T<:AbstractFloat

    œï = get_Œ¶(œïname, œïœµ)

    if fixed_sampler_func == nothing
        # the default way to generate sample
        init_func = j->sampler(U‚ÇÄ,1)[:]
    else
        # if one wants to use a fix collection of samples, e.g., denoted as pts,
        # then we can simply choose fixed_sampler_func = j-> pts[j]
        init_func = j->fixed_sampler_func(j)
    end

    num_para = flow.num_para
    M = flow.total_num_para
    test_func = (x,t,p) -> test_func_train(x, p, U‚ÇÄ, U‚ÇÅ)
    test_func_para = flow

    if ptype == "pmap"
        data = pmap(j-> one_path_optimize_dyn_b(flow, test_func, test_func_para, N,
                                        offset, init_func, j, solver, œï),
            1:numsample)
    else
        data = [zeros(T,1+flow.total_num_para) for j=1:numsample]
        Threads.@threads for j = 1:numsample
            data[j] = one_path_optimize_dyn_b(flow, test_func, test_func_para, N,
                                              offset, init_func, j, solver, œï)
        end
    end

    #return get_mean_sec_moment(data)
    return get_mean_entropy(data, œï)
end


"""
train_NN_int
"""
function train_NN_int(U‚ÇÄ::Potential{T}, U‚ÇÅ::Potential{T},
        flow::DynTrain{T},
        N::Int, numsample_max::Int,
        train_step::Int,
        h::T, decay::T,
        gpts::AbstractMatrix{T}, gpts_sampler::Union{Function,Nothing};
        œïname="msq", œïœµ=T(1.0e-3),
        offset::Int=0,
        biased_func=nothing,
        solver::Function=RK4,
        ref_value::T=T(1.0),
        seed::Int64=-1,
        verbose::Bool=false, printpara::Bool=false,
        œÅ=T(0.5), c=T(0.5),
        to_normalize::Bool=true,
        max_search_iter::Int=10,
        sample_num_repeat::Int=1,
        print_sample::Bool=false,
        numsample_min::Int=-1,
        savepara::Bool=false,
        ptype="threads",
        showprogress=true,
        compute_rela_divg=true,
        quiet::Bool=true) where T<:AbstractFloat

    œï = get_Œ¶(œïname, œïœµ)

    (offset < 0 || offset > N) ? error("Incorrect offset") : nothing

    fixed_sampler_func = j->gpts[:,j]
    loss_func(m)=get_data_err_var(U‚ÇÄ, U‚ÇÅ, flow, N, offset, m,
                                  œïname=œïname, œïœµ=œïœµ,
                                  fixed_sampler_func=fixed_sampler_func,
                                  solver=solver, ptype=ptype)[3]
    stat_opt_func(m) = stat_optimize_dyn_b(U‚ÇÄ, U‚ÇÅ, flow, N, offset, m,
                                  œïname=œïname, œïœµ=œïœµ,
                                  fixed_sampler_func=fixed_sampler_func,
                                  solver=solver, ptype=ptype)

    return train_NN_template(stat_opt_func, loss_func,
                      flow, numsample_max, train_step,
                      h, decay, gpts, gpts_sampler, œï,
                      biased_func=biased_func,
                      ref_value=ref_value, seed=seed,
                      verbose=verbose, printpara=printpara,
                      œÅ=œÅ, c=c, to_normalize=to_normalize,
                      max_search_iter=max_search_iter,
                      sample_num_repeat=sample_num_repeat,
                      print_sample=print_sample,
                      numsample_min=numsample_min, savepara=savepara,
                      showprogress=showprogress,
                      compute_rela_divg=compute_rela_divg,
                      quiet=quiet)
end
